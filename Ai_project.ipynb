{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNb4WXnNKW+NJeKp08YxC5N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SrinidhiNagaraju15/My-project/blob/main/Ai_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "id": "tARPhp5iUnD-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ad91c57-4a63-4f82-d1d1-d9d768669826"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_recall_fscore_support, classification_report\n",
        "import string\n",
        "\n",
        "# Step 2: Download necessary NLTK resources (No Error Messages)\n",
        "nltk_data_packages = [\n",
        "    \"punkt\", \"stopwords\", \"wordnet\", \"omw-1.4\", \"averaged_perceptron_tagger\"\n",
        "]\n",
        "for package in nltk_data_packages:\n",
        "    nltk.download(package, quiet=True)  # No messages, no prompts\n",
        "\n",
        "# Step 3: Load dataset\n",
        "df = pd.read_csv('/content/DatasetReviewsAndSentiments.csv')\n",
        "\n",
        "# Initialize lemmatizer and stop words\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stop_words.discard('not')  # Ensure 'not' is not removed\n",
        "\n",
        "# Step 4: Preprocessing function (FIXED)\n",
        "def PreProcessText(review):\n",
        "    if not isinstance(review, str) or review.strip() == \"\":  # Handle missing/NaN values\n",
        "        return \"\"\n",
        "\n",
        "    tokens = word_tokenize(review.lower())  # Tokenization\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word.isalnum() and word not in stop_words]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Apply preprocessing\n",
        "df['Review'] = df['Review'].apply(PreProcessText)\n",
        "\n",
        "# Step 5: TF-IDF Vectorization\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1, 3))\n",
        "X = vectorizer.fit_transform(df['Review'])\n",
        "y = df['Label']\n",
        "\n",
        "print(y.value_counts())\n",
        "\n",
        "# Step 6: Splitting dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify=y)\n",
        "\n",
        "# Step 7: Model training with GridSearchCV\n",
        "model = MultinomialNB()\n",
        "param_grid = {'alpha': [0.1, 0.5, 0.7], 'fit_prior': [True, False]}\n",
        "stratified_kfold = StratifiedKFold(n_splits=5)\n",
        "grid_search = GridSearchCV(model, param_grid, cv=stratified_kfold, scoring='f1_weighted')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Step 8: Model evaluation\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "y_pred = grid_search.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
        "print(f\"Confusion Matrix:\\n{cm}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1_score}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Step 9: Prediction function\n",
        "def predict_sentiment(review):\n",
        "    review_processed = PreProcessText(review)\n",
        "    review_vectorized = vectorizer.transform([review_processed])\n",
        "    prediction = grid_search.predict(review_vectorized)\n",
        "    return prediction[0]\n",
        "\n",
        "# Step 10: Sample reviews for testing\n",
        "reviews = [\n",
        "    \"This app is amazing! I've never had any issues and it works perfectly.\",\n",
        "    \"Scam! They charged me without my consent and the app doesn't even work.\",\n",
        "    \"Great app for tracking my workouts. Highly recommend it to anyone!\",\n",
        "    \"Totally fake! This app is just a clone of another one and it crashes all the time.\",\n",
        "    \"I've been using this app for months and it's been very reliable and useful.\",\n",
        "    \"Warning! This app stole my personal information. Do not download.\",\n",
        "    \"Fantastic user interface and very helpful customer support.\",\n",
        "    \"Terrible. It's filled with ads and doesn't do what it promises.\",\n",
        "    \"Love the new features in the latest update. Well done!\",\n",
        "    \"Fake reviews everywhere. This app is a complete fraud.\"\n",
        "]\n",
        "\n",
        "for review in reviews:\n",
        "    predicted_sentiment = predict_sentiment(review)\n",
        "    print(f\"Review: {review}\")\n",
        "    print(f\"Predicted sentiment: {predicted_sentiment}\")\n",
        "    if predicted_sentiment == \"negative\":\n",
        "        print(\"App is Fraud\")\n",
        "    else:\n",
        "        print(\"App is Not Fraud\")\n",
        "\n",
        "# Step 11: User input for review analysis\n",
        "new_review = input(\"Enter a review to detect its sentiment: \")\n",
        "predicted_sentiment = predict_sentiment(new_review)\n",
        "print(f\"Predicted sentiment for the review: {predicted_sentiment}\")\n",
        "if predicted_sentiment == \"negative\":\n",
        "    print(\"App is Fraud\")\n",
        "else:\n",
        "    print(\"App is Not Fraud\")\n",
        "\n",
        "# Step 12: Function to display TF-IDF scores\n",
        "import numpy as np\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def display_tfidf_scores(review):\n",
        "    # Preprocess the input review\n",
        "    review_processed = PreProcessText(review)\n",
        "\n",
        "    # Tokenize words manually\n",
        "    words = review_processed.split()\n",
        "\n",
        "    # Transform the review using the trained TF-IDF vectorizer\n",
        "    review_vectorized = vectorizer.transform([review_processed])\n",
        "\n",
        "    # Get feature names from TF-IDF vectorizer\n",
        "    feature_names = np.array(vectorizer.get_feature_names_out())  # Convert to NumPy array for safe indexing\n",
        "\n",
        "    # Convert sparse matrix to array and flatten it\n",
        "    tfidf_scores = review_vectorized.toarray().flatten()\n",
        "\n",
        "    # Get indices where TF-IDF scores are nonzero\n",
        "    nonzero_indices = tfidf_scores.nonzero()[0]  # Only take features that exist\n",
        "\n",
        "    # Create dictionary of word/ngram -> TF-IDF score\n",
        "    tfidf_dict = {feature_names[i]: tfidf_scores[i] for i in nonzero_indices}\n",
        "\n",
        "    # Handle out-of-vocabulary (OOV) words\n",
        "    oov_words = [word for word in words if word not in feature_names]\n",
        "    for oov in oov_words:\n",
        "        tfidf_dict[oov] = 0.0001  # Assign small weight to unseen words\n",
        "\n",
        "    # Sort dictionary by TF-IDF scores in descending order\n",
        "    tfidf_dict_sorted = dict(sorted(tfidf_dict.items(), key=lambda item: item[1], reverse=True))\n",
        "\n",
        "    # Display TF-IDF scores\n",
        "    print(f\"\\nTF-IDF scores for review: '{review}'\")\n",
        "    for word, score in tfidf_dict_sorted.items():\n",
        "        print(f\"{word}: {score}\")\n",
        "\n",
        "# Call function to display TF-IDF scores for user input\n",
        "display_tfidf_scores(new_review)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-38M5It9ydYb",
        "outputId": "c344751a-159e-4d4c-d2a6-a29fe74f2616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label\n",
            "negative    261\n",
            "positive    239\n",
            "Name: count, dtype: int64\n",
            "Best parameters: {'alpha': 0.1, 'fit_prior': True}\n",
            "Accuracy: 0.5151515151515151\n",
            "Confusion Matrix:\n",
            "[[41 45]\n",
            " [35 44]]\n",
            "Precision: 0.5178843431356737\n",
            "Recall: 0.5151515151515151\n",
            "F1 Score: 0.5146170701726257\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.54      0.48      0.51        86\n",
            "    positive       0.49      0.56      0.52        79\n",
            "\n",
            "    accuracy                           0.52       165\n",
            "   macro avg       0.52      0.52      0.51       165\n",
            "weighted avg       0.52      0.52      0.51       165\n",
            "\n",
            "Review: This app is amazing! I've never had any issues and it works perfectly.\n",
            "Predicted sentiment: positive\n",
            "App is Not Fraud\n",
            "Review: Scam! They charged me without my consent and the app doesn't even work.\n",
            "Predicted sentiment: negative\n",
            "App is Fraud\n",
            "Review: Great app for tracking my workouts. Highly recommend it to anyone!\n",
            "Predicted sentiment: negative\n",
            "App is Fraud\n",
            "Review: Totally fake! This app is just a clone of another one and it crashes all the time.\n",
            "Predicted sentiment: positive\n",
            "App is Not Fraud\n",
            "Review: I've been using this app for months and it's been very reliable and useful.\n",
            "Predicted sentiment: negative\n",
            "App is Fraud\n",
            "Review: Warning! This app stole my personal information. Do not download.\n",
            "Predicted sentiment: positive\n",
            "App is Not Fraud\n",
            "Review: Fantastic user interface and very helpful customer support.\n",
            "Predicted sentiment: positive\n",
            "App is Not Fraud\n",
            "Review: Terrible. It's filled with ads and doesn't do what it promises.\n",
            "Predicted sentiment: positive\n",
            "App is Not Fraud\n",
            "Review: Love the new features in the latest update. Well done!\n",
            "Predicted sentiment: negative\n",
            "App is Fraud\n",
            "Review: Fake reviews everywhere. This app is a complete fraud.\n",
            "Predicted sentiment: positive\n",
            "App is Not Fraud\n",
            "Enter a review to detect its sentiment: Very useful app, helps me keep track of my expenses easily\n",
            "Predicted sentiment for the review: negative\n",
            "App is Fraud\n",
            "\n",
            "TF-IDF scores for review: 'Very useful app, helps me keep track of my expenses easily'\n",
            "app help: 0.24618831355667867\n",
            "app help keep: 0.24618831355667867\n",
            "easily: 0.24618831355667867\n",
            "expense: 0.24618831355667867\n",
            "expense easily: 0.24618831355667867\n",
            "help: 0.24618831355667867\n",
            "help keep: 0.24618831355667867\n",
            "help keep track: 0.24618831355667867\n",
            "keep track: 0.24618831355667867\n",
            "keep track expense: 0.24618831355667867\n",
            "track: 0.24618831355667867\n",
            "track expense: 0.24618831355667867\n",
            "track expense easily: 0.24618831355667867\n",
            "useful app: 0.24618831355667867\n",
            "useful app help: 0.24618831355667867\n",
            "useful: 0.20365065074523925\n",
            "keep: 0.20146316142292797\n",
            "app: 0.09385478710378437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4BdQQRrCyj9o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}